{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MIMIC-III",
   "id": "9a3eebb8798f35cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:33:21.534088Z",
     "start_time": "2024-10-01T05:33:21.525296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from models.cvae import VariationalAutoencoder, vae_loss_fn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "seed = 804"
   ],
   "id": "adc9c7752b3ddf3d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:33:21.551678Z",
     "start_time": "2024-10-01T05:33:21.542743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MIMICDATASET(Dataset):\n",
    "    def __init__(self, x_t,x_s, y, train=None, transform=None):\n",
    "        # Transform\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.xt = x_t\n",
    "        self.xs = x_s\n",
    "        self.y = y\n",
    "\n",
    "    def return_data(self):\n",
    "        return self.xt, self.xs, self.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xt)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.xt[idx]\n",
    "        stat = self.xs[idx]\n",
    "        sample_y = self.y[idx]\n",
    "        return sample, stat, sample_y"
   ],
   "id": "1432491f62a3cbe5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:58:45.534996Z",
     "start_time": "2024-10-01T05:58:45.525287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def LR_evaluation(test_S, test_X, test_y):\n",
    "    \n",
    "    N,D = test_X.shape\n",
    "    _,d = test_S.shape\n",
    "    \n",
    "    X_all = np.hstack([test_S, test_X.reshape((N,D))])\n",
    "    y_all = test_y\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_all = scaler.fit_transform(X_all)\n",
    "    \n",
    "    print(X_all.shape, y_all.shape)\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X_all, y_all, stratify=y_all, random_state=1)\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(Xtr, ytr)\n",
    "    \n",
    "    score = metrics.roc_auc_score(yte, clf.decision_function(Xte))\n",
    "    print('Test AUROC score:', score)\n"
   ],
   "id": "a6ee0e7a98d9b859",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:33:21.659792Z",
     "start_time": "2024-10-01T05:33:21.655231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def MIMIC_syn_data(model_name, folder = \"Synthetic_MIMIC\"):\n",
    "    \n",
    "    model_list = [\"vae\", \"medDiff\", \"flexgen\"]\n",
    "    if model_name not in model_list:\n",
    "        raise ValueError(f\"model_name must be in {model_list}\")\n",
    "\n",
    "    static_npy_path = folder + \"/\" + model_name + \"_static.npy\"\n",
    "    temporal_npy_path =  folder + \"/\" + model_name + \"_temporal.npy\"\n",
    "    \n",
    "    test_S = np.load(static_npy_path)\n",
    "    test_X = np.load(temporal_npy_path)\n",
    "    \n",
    "    df_pop = pd.read_csv('FIDDLE_mimic3/population/mortality_48h.csv')\n",
    "    test_y = torch.tensor(df_pop[\"mortality_LABEL\"].values).to(torch.float32)\n",
    "    \n",
    "    return test_S, test_X, test_y"
   ],
   "id": "97229aae902e244c",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Original",
   "id": "200bafbc1dc6570e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T05:33:32.873681Z",
     "start_time": "2024-10-01T05:33:21.669780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test_S = np.load('FIDDLE_mimic3/features/mortality_48h/s.npz')\n",
    "# test_X = np.load('FIDDLE_mimic3/features/mortality_48h/X.npz')\n",
    "# test_S = torch.sparse_coo_tensor(torch.tensor(test_S['coords']), torch.tensor(test_S['data'])).to_dense().to(torch.float32)\n",
    "# test_X = torch.sparse_coo_tensor(torch.tensor(test_X['coords']), torch.tensor(test_X['data'])).to_dense().to(torch.float32)\n",
    "# \n",
    "# df_pop = pd.read_csv('FIDDLE_mimic3/population/mortality_48h.csv')\n",
    "# test_y = torch.tensor(df_pop[\"mortality_LABEL\"].values).to(torch.float32)\n",
    "# \n",
    "# test_X = test_X.sum(dim=1)\n",
    "# LR_evaluation(test_S, test_X, test_y)"
   ],
   "id": "c9d98a02e413126c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8577, 7403) torch.Size([8577])\n",
      "Test AUROC score: 0.8700061210321128\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## VAE",
   "id": "c2b155c991ac12ec"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T06:18:57.153017Z",
     "start_time": "2024-10-01T06:18:55.964220Z"
    }
   },
   "source": [
    "test_S, test_X, test_y = MIMIC_syn_data(\"vae\")\n",
    "LR_evaluation(test_S, test_X, test_y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8577, 7403) torch.Size([8577])\n",
      "Test AUROC score: 1.0\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MedDiff",
   "id": "71451809f52f11e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T06:16:27.056159Z",
     "start_time": "2024-10-01T06:16:25.946222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_S, test_X, test_y = MIMIC_syn_data(\"medDiff\")\n",
    "y = np.concatenate((np.zeros(2000), np.ones(2000)))\n",
    "LR_evaluation(test_S, test_X, y)"
   ],
   "id": "e3b7dfda327d432c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 7403) (4000,)\n",
      "Test AUROC score: 0.50344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FlexGen",
   "id": "d304b82b05ff7516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T06:09:39.297153Z",
     "start_time": "2024-10-01T06:09:38.188526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_S, test_X, test_y = MIMIC_syn_data(\"flexgen\")\n",
    "y = np.concatenate((np.zeros(2000), np.ones(2000)))\n",
    "LR_evaluation(test_S, test_X, y)"
   ],
   "id": "4d1560d5636e1ad4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 7403) (4000,)\n",
      "Test AUROC score: 0.50344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
