{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from main import MIMICDATASET"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.59 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# raw data 与 mort\n",
    "train_raw_x = pd.read_csv('m_train.csv', index_col=[0, 1, 2], header = [0, 1, 2, 3])\n",
    "train_mort_y = pd.read_csv('my_train.csv', index_col=[0, 1])\n",
    "\n",
    "# 之后用于验证的diagnosis数据\n",
    "diagnosis = pd.read_csv('ms_train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw_x = pd.read_csv('m_test.csv', index_col=[0, 1, 2], header = [0, 1, 2, 3])\n",
    "test_mort_y = pd.read_csv('my_test.csv', index_col=[0, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查 head 确保导入成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mort_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>admission_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>211552</td>\n",
       "      <td>HYPOTENSION</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>EMERGENCY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>228232</td>\n",
       "      <td>CHRONIC RENAL FAILURE/SDA</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ELECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>HEMORRHAGIC CVA</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>EMERGENCY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>194540</td>\n",
       "      <td>229441</td>\n",
       "      <td>BRAIN MASS</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>EMERGENCY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>112213</td>\n",
       "      <td>232669</td>\n",
       "      <td>PANCREATIC CANCER/SDA</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ELECTIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  icustay_id                  diagnosis  \\\n",
       "0           3   145834      211552                HYPOTENSION   \n",
       "1           6   107064      228232  CHRONIC RENAL FAILURE/SDA   \n",
       "2           9   150750      220597            HEMORRHAGIC CVA   \n",
       "3          11   194540      229441                 BRAIN MASS   \n",
       "4          12   112213      232669      PANCREATIC CANCER/SDA   \n",
       "\n",
       "               ethnicity admission_type  \n",
       "0                  WHITE      EMERGENCY  \n",
       "1                  WHITE       ELECTIVE  \n",
       "2  UNKNOWN/NOT SPECIFIED      EMERGENCY  \n",
       "3                  WHITE      EMERGENCY  \n",
       "4                  WHITE       ELECTIVE  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mort_y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE 辅助数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "train_raw_x, train_mort_y = sm.fit_resample(train_raw_x, train_mort_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 显微镜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_dataset = MIMICDATASET(x_path='m_test.csv', x_s_path='ms_test.csv', y_path='my_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察数据集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mimic_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察单个数据点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, sample_y = mimic_dataset[0]\n",
    "print(f\"Sample: {sample}, Sample_y: {sample_y}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看原始dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_data, label_data = mimic_dataset.return_data()\n",
    "print(ehr_data.head())\n",
    "print(label_data.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批量观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(mimic_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    print(f\"Batch {i} -> Number of elements in tuple: {len(data)}\")\n",
    "\n",
    "    for j, element in enumerate(data):\n",
    "        print(f\"Element {j} in batch {i}: {element}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别 numerical data 后 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择数值列\n",
    "numeric_cols = train_raw_x.select_dtypes(include=['number']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择标准差大于阈值的列\n",
    "threshold = 0.5\n",
    "std_devs = train_raw_x[numeric_cols].std()\n",
    "numeric_cols_filtered = std_devs[std_devs > threshold].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_raw_x[numeric_cols_filtered] = scaler.fit_transform(train_raw_x[numeric_cols_filtered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_cols_filtered)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化 lr\n",
    "clf = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理 mort column，保证只有一个 mort column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mort_y = train_mort_y['mort_icu']\n",
    "test_mort_y = test_mort_y['mort_icu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_raw_x, train_mort_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_raw_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率\n",
    "accuracy = accuracy_score(test_mort_y, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(test_mort_y, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# 计算精度\n",
    "precision = precision_score(test_mort_y, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(test_mort_y, y_pred)\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = clf.predict_proba(test_raw_x)[:, 1]  # 获取正类别（'1'）的概率预测值\n",
    "\n",
    "\n",
    "# 计算AUC-ROC曲线下面积\n",
    "roc_auc = roc_auc_score(test_mort_y, y_pred_prob)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "# 获取用于绘制ROC曲线的值\n",
    "fpr, tpr, _ = roc_curve(test_mort_y, y_pred_prob)\n",
    "\n",
    "# 绘制曲线\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  # 绘制对角线\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm.fit(train_raw_x, train_mort_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rdm.predict(test_raw_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率\n",
    "accuracy = accuracy_score(test_mort_y, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(test_mort_y, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# 计算精度\n",
    "precision = precision_score(test_mort_y, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# 计算F1分数\n",
    "f1 = f1_score(test_mort_y, y_pred)\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取正类别（'1'）的概率预测值\n",
    "y_pred_prob = clf.predict_proba(test_raw_x)[:, 1]\n",
    "\n",
    "# 计算AUC-ROC曲线下面积\n",
    "roc_auc = roc_auc_score(test_mort_y, y_pred_prob)\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "# 获取用于绘制ROC曲线的值\n",
    "fpr, tpr, _ = roc_curve(test_mort_y, y_pred_prob)\n",
    "\n",
    "# 绘制曲线\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')  # 绘制对角线\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosis处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global mapping dictionaries\n",
    "g_map = {'ELECTIVE': 1, 'URGENT': 2, 'EMERGENCY': 3, '': 0, 'NaN': 0, 'Unknown': 0, 'Other': 0}\n",
    "e_map = {'ASIAN': 1, 'BLACK': 2, 'AFRICAN AMERICAN': 2, 'WHITE': 3, 'HISPANIC': 4, 'LATINO':4, 'NATIVE': 5, 'NaN': 0, '': 0}\n",
    "\n",
    "# Convert gender to numbers\n",
    "def transform_ad(gender_series):\n",
    "    global g_map\n",
    "    return {'gender': gender_series.fillna('').apply(lambda s: g_map.get(s, g_map.get('')))}\n",
    "    \n",
    "# Convert ethnicity to numbers\n",
    "def transform_eth(ethnicity_series):\n",
    "    global e_map\n",
    "    return {'ethnicity': ethnicity_series.fillna('').apply(lambda s: e_map.get(s, e_map.get('')))}\n",
    "\n",
    "# Convert diagnosis into numbers, considering multiple diagnoses separated by semicolon\n",
    "def transform_dx_into_id(df, column_name='diagnosis'):\n",
    "    # Fill NaN values with 'nodx'\n",
    "    df[column_name].fillna('nodx', inplace=True)\n",
    "    \n",
    "    # Get the unique diagnoses by splitting them at the semicolon and flattening the list\n",
    "    all_diagnoses = df[column_name].apply(lambda x: x.split(';')).explode().unique()\n",
    "    \n",
    "    # Factorize the unique diagnoses\n",
    "    dict_dx_val, dict_dx_key = pd.factorize(all_diagnoses)\n",
    "    \n",
    "    # Create a dictionary for mapping\n",
    "    dictionary = dict(zip(dict_dx_key, dict_dx_val))\n",
    "    \n",
    "    # Map each diagnosis to its respective id\n",
    "    df[column_name] = df[column_name].apply(lambda x: ';'.join([str(dictionary[i]) for i in x.split(';')]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Gender and ethnicity maps\n",
    "ad_map = {'ELECTIVE': 1, 'URGENT': 2, 'EMERGENCY': 3, '': 0, 'NaN': 0, 'Unknown': 0, 'Other': 0}\n",
    "e_map = {'ASIAN': 1, 'BLACK': 2, 'AFRICAN AMERICAN': 2, 'WHITE': 3, 'HISPANIC': 4, 'LATINO':4, 'NATIVE': 5, 'NaN': 0, '': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('ms_train.csv')\n",
    "\n",
    "# Apply transformations\n",
    "df = transform_dx_into_id(df, 'diagnosis')  # transform diagnosis\n",
    "transformed_gender_series = transform_ad(df['admission_type'])  # transform admission_type\n",
    "transformed_ethnicity_series = transform_eth(df['ethnicity'])  # transform ethnicity\n",
    "\n",
    "# Add new columns for transformed data\n",
    "df['transformed_ethnicity'] = transformed_ethnicity_series['ethnicity']\n",
    "df['transformed_admission_type'] = transformed_gender_series['gender']\n",
    "\n",
    "# Save the transformed DataFrame back to a new CSV file\n",
    "df.to_csv('ms_train_transformed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
